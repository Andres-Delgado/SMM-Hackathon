{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media Mining - Hackathon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Popularity of Online Content\n",
    "Replicate and extend the article (link below) for predicting online content popularity using Twitter hashtags. Applying a method to a different dataset often entails making different choices from the ones of the original authors. Describe your experience and motivate your unique approach.\n",
    "\n",
    "### Dataset\n",
    "Using the Twitter Streaming API, you will collect a dataset of Twitter hashtags.\n",
    "\n",
    "### References\n",
    "- [Link to article](http://www.hpl.hp.com/research/scl/papers/predictions/predictions.pdf)\n",
    "- [Twitter Streaming API](https://developer.twitter.com/en/docs/tweets/sample-realtime/overview/GET_statuse_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import json\n",
    "import os\n",
    "\n",
    "CONSUMER_KEY = 'n3klbsDYyvvk1IxCEvm7W3tGw'\n",
    "CONSUMER_SECRET ='CJZ71dbUlhjDu7DyzawOCBMPkltdpw6816WZ3WUgC8rbOcKSs8'\n",
    "OAUTH_TOKEN = '1031697780417417216-TwltGeXHoG0eybrj8tF1AAckCj2bDb'\n",
    "OAUTH_TOKEN_SECRET = 'skAVmJwY1BhbrPWAeJB5uOWMacpikpYw2n8XAXnUI3TwU'\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "tStream = twitter.TwitterStream(auth = auth)\n",
    "tSample = tStream.statuses.sample() # stream sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NameFile() creates a file name to make sure we don't overwite previous sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NameFile():\n",
    "    pathName = os.path.join('Data', 'Tweets')\n",
    "    \n",
    "    if not os.path.isfile(pathName + '.json'):\n",
    "        return pathName + '.json'\n",
    "    \n",
    "    count = 1\n",
    "    while (os.path.isfile(pathName + str(count) + '.json')):\n",
    "        count += 1\n",
    "            \n",
    "    return pathName + str(count) + '.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StoreTweets() writes sampled tweets to ../Data/Tweets.json\n",
    "Filters out deleted tweets and tweets without hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StoreTweets(pathToTweets, tSample):\n",
    "    with open(os.path.join(pathToTweets), 'w') as f:\n",
    "        f.write('[')\n",
    "\n",
    "        count = 0\n",
    "        for tweet in tSample:\n",
    "            #if (list(tweet.keys())[0] != 'delete') and (tweet.get('entities', False)):\n",
    "            if (tweet.get('delete', False) is False) and (tweet.get('entities', False)):\n",
    "                if tweet['entities'].get('hashtags', False):\n",
    "                    count += 1\n",
    "                    json.dump(tweet, f)\n",
    "                    if count < 100: f.write(',\\n')\n",
    "                    else: break\n",
    "        f.write(']')\n",
    "        f.close()\n",
    "        print(count, \"tweets written to file\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pathToTweets = NameFile()\n",
    "#StoreTweets(pathToTweets, tSample)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoadFile() opens the specified file and returns a json object of its contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadFile(pathName):    \n",
    "    if os.path.isfile(pathName):\n",
    "        file = open(os.path.join(pathName), 'r')\n",
    "        return json.load(file)\n",
    "    else: print(\"File not in directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = LoadFile(os.path.join('Data', 'Tweets.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StoreHashtags() extracts all unique hashtags from LoadTweets() and writes them to Tweets(#)-Hashtags.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StoreHashtags(pathName, givenTweets):\n",
    "    hashtagList = []\n",
    "    for tweet in givenTweets:\n",
    "        for hTag in tweet['entities']['hashtags']:\n",
    "            hashtagList.append(hTag['text'])\n",
    "        \n",
    "    hashtagList = list(set(hashtagList))\n",
    "    newPath = pathName[:-5] + \"-Hashtags.json\"\n",
    "\n",
    "    with open(newPath, 'w') as f:    \n",
    "        json.dump(hashtagList, f)\n",
    "        f.close()\n",
    "    print(\"Stored all unique hashtags in {}\".format(newPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StoreHashtags(os.path.join('Data', 'Tweets.json'), tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hashtagList = LoadFile(os.path.join('Data', 'Tweets-Hashtags.json'))\n",
    "#print(json.dumps(hashtags, indent = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, tag in enumerate(hashtagList):\n",
    "    print(tag)\n",
    "    if i > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### StoreDict() takes in the list of hashtag strings (hashtagList), constructs a dictionary of hashtag dictionaries, writes them to Tweets(#)-Hashtags-Dict.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StoreDictionary(pathName, givenHTList, numberOfDays):\n",
    "    # use of other hashtags, media(type?), user_mentions, filter_level\n",
    "    details = {'occurrences': 0, 'created_at': [], 'followers_count': [], 'lang': {}}\n",
    "    \n",
    "    days = {}    \n",
    "    for i in range(numberOfDays):\n",
    "        days.setdefault('day' + str(i), dict(details))\n",
    "\n",
    "    hashtagsDict = {}\n",
    "    for i, tag in enumerate(givenHTList):\n",
    "        hashtagsDict.setdefault(tag, dict(days))\n",
    "    \n",
    "    newPath = pathName[:-5] + \"-Dict.json\"\n",
    "    with open(newPath, 'w') as f:    \n",
    "        json.dump(hashtagsDict, f)\n",
    "        f.close()\n",
    "    print(\"Stored the hashtag dictionary in {}\".format(newPath))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StoreDictionary(os.path.join('Data', 'Tweets-Hashtags_test.json'), hashtagList, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = LoadFile(os.path.join('Data', 'Tweets-Hashtags-Dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique hashtags:\", len(hashtags), end = '\\n\\n')\n",
    "for tag, content in hashtags.items():\n",
    "    print(\"Hashtag:\", tag)\n",
    "    print(json.dumps(content, indent = 1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtag Dictionary: \n",
    "- **keys:** hashtag string\n",
    "- **values:** dictionary of day objects\n",
    "\n",
    "### day objects:\n",
    "- **occurences:** number of occurences of hashtag for given day\n",
    "- **created_at:** list (strings) of creation times of all (or some?) tweets using hashtag\n",
    "- **followers_count:** list (ints) of number followers the user has who posted the tweet\n",
    "- **lang:** dictionary to count the number of self-declared languages by user\n",
    "    - \"en\": 100\n",
    "    - \"es\": 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added by Logan\n",
    "Search function demonstrated below.\n",
    "Run to see example with #turkey from Oct 12 to Oct 14 -- takes a minute to run\n",
    "Also can use search.search_by_hashtag() to search one range only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 12, number of tweets: 1184\n",
      "day: 13, number of tweets: 94\n"
     ]
    }
   ],
   "source": [
    "#search function is under ./Code/search.py\n",
    "import sys\n",
    "sys.path.append(\"./Code/\") #add the path with the code so that it can be imported\n",
    "\n",
    "import search\n",
    "\n",
    "#searches for #turkey from oct 12 to oct 14 then prints debug stats\n",
    "#function returns a list of dicts with the tweets and information\n",
    "#read the comments in search.py for more information\n",
    "\n",
    "results = search.searchOverRange(\"#turkey\", 2018, 10, 12, 2018, 10, 14, debug=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cache-control': 'no-cache, no-store, must-revalidate, pre-check=0, post-check=0', 'content-disposition': 'attachment; filename=json.json', 'content-encoding': 'gzip', 'content-length': '56822', 'content-type': 'application/json;charset=utf-8', 'date': 'Thu, 18 Oct 2018 17:12:49 GMT', 'expires': 'Tue, 31 Mar 1981 05:00:00 GMT', 'last-modified': 'Thu, 18 Oct 2018 17:12:49 GMT', 'pragma': 'no-cache', 'server': 'tsa_b', 'set-cookie': 'personalization_id=\"v1_smyOoxKH425CVXX0Dxl3ig==\"; Expires=Sat, 17 Oct 2020 17:12:49 GMT; Path=/; Domain=.twitter.com, lang=en; Path=/, guest_id=v1%3A153988276971541185; Expires=Sat, 17 Oct 2020 17:12:49 GMT; Path=/; Domain=.twitter.com', 'status': '200 OK', 'strict-transport-security': 'max-age=631138519', 'x-access-level': 'read-write', 'x-connection-hash': 'f7464f70a9db12ab4a5343f5606120da', 'x-content-type-options': 'nosniff', 'x-frame-options': 'SAMEORIGIN', 'x-rate-limit-limit': '180', 'x-rate-limit-remaining': '128', 'x-rate-limit-reset': '1539882995', 'x-response-time': '222', 'x-transaction': '007d3eee00dad1ef', 'x-twitter-response-tags': 'BouncerCompliant', 'x-xss-protection': '1; mode=block; report=https://twitter.com/i/xss_report'}\n"
     ]
    }
   ],
   "source": [
    "#prints the twitter metadata\n",
    "print(results[1][\"metadata\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
